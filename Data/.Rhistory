mutate(topic_model = future_map(K, ~stm(speechcorp, K = .,
verbose = FALSE)))
heldout <- make.heldout(speechcorp)
k_result <- many_models %>%
mutate(exclusivity = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, speechcorp),
eval_heldout = map(topic_model, eval.heldout, heldout$missing),
residual = map(topic_model, checkResiduals, speechcorp),
bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound = bound + lfact,
iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))
k_result
k_result %>%
transmute(K,
`Lower bound` = lbound,
Residuals = map_dbl(residual, "dispersion"),
`Semantic coherence` = map_dbl(semantic_coherence, mean),
`Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
gather(Metric, Value, -K) %>%
ggplot(aes(K, Value, color = Metric)) +
geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
facet_wrap(~Metric, scales = "free_y") +
labs(x = "K (number of topics)",
y = NULL,
title = "Model diagnostics by number of topics",
subtitle = "These diagnostics indicate that a good number of topics would be around 60")
topic_model <- k_result %>%
filter(K == 4) %>%
pull(topic_model) %>%
.[[1]]
topic_model
library(tidytext)
td_beta <- tidy(topic_model)
td_gamma <- tidy(topic_model, matrix = "gamma",
document_names = rownames(speechcorp))
library(ggthemes)
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
gamma_terms <- td_gamma %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
arrange(desc(gamma)) %>%
left_join(top_terms, by = "topic") %>%
mutate(topic = paste0("Topic ", topic),
topic = reorder(topic, gamma))
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.15,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
topic_model <- k_result %>%
filter(K == 6) %>%
pull(topic_model) %>%
.[[1]]
topic_model
library(tidytext)
td_beta <- tidy(topic_model)
td_gamma <- tidy(topic_model, matrix = "gamma",
document_names = rownames(speechcorp))
library(ggthemes)
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
gamma_terms <- td_gamma %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
arrange(desc(gamma)) %>%
left_join(top_terms, by = "topic") %>%
mutate(topic = paste0("Topic ", topic),
topic = reorder(topic, gamma))
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.15,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
speeches$dates<-as.numeric(speeches$dates)
attach(speeches)
estimate<-estimateEffect(~dates, topicmodel)
speeches$dates<-as.numeric(speeches$dates)
attach(speeches)
estimate<-estimateEffect(~dates, topic_model)
plot.estimateEffect(estimate, covariate='dates',method='continuous',topics=c(1,7),model='frex')
rm(dates)
speeches$dates<-as.numeric(speeches$dates)
attach(speeches)
estimate<-estimateEffect(~dates, topic_model)
plot.estimateEffect(estimate, covariate='dates',method='continuous',topics=c(1,7),model='frex')
speeches$dates<-as.numeric(speeches$dates)
attach(speeches)
estimate<-estimateEffect(~dates, topic_model)
plot.estimateEffect(estimate, covariate='dates',method='continuous',topics=c(1,6),model='frex')
speeches$dates<-as.numeric(speeches$dates)
attach(speeches)
estimate<-estimateEffect(~dates, topic_model)
plot.estimateEffect(estimate, covariate='dates',method='continuous',topics=c(1,3),model='frex')
?plot.estimateEffect
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.18,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.12,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
library(knitr)
gamma_terms %>%
select(topic, gamma, terms) %>%
kable(digits = 3,
col.names = c("Topic", "Expected proportion", "Top 7 terms"))
topic_model <- k_result %>%
filter(K == 4) %>%
pull(topic_model) %>%
.[[1]]
topic_model
library(tidytext)
td_beta <- tidy(topic_model)
td_gamma <- tidy(topic_model, matrix = "gamma",
document_names = rownames(speechcorp))
library(ggthemes)
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
gamma_terms <- td_gamma %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
arrange(desc(gamma)) %>%
left_join(top_terms, by = "topic") %>%
mutate(topic = paste0("Topic ", topic),
topic = reorder(topic, gamma))
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.12,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.15,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
library(knitr)
gamma_terms %>%
select(topic, gamma, terms) %>%
kable(digits = 3,
col.names = c("Topic", "Expected proportion", "Top 7 terms"))
k_result %>%
transmute(K,
`Lower bound` = lbound,
Residuals = map_dbl(residual, "dispersion"),
`Semantic coherence` = map_dbl(semantic_coherence, mean),
`Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
gather(Metric, Value, -K) %>%
ggplot(aes(K, Value, color = Metric)) +
geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
facet_wrap(~Metric, scales = "free_y") +
labs(x = "K (number of topics)",
y = NULL,
title = "Model diagnostics by number of topics",
subtitle = "These diagnostics indicate that a good number of topics would be around 4")
topic_model <- k_result %>%
filter(K == 8) %>%
pull(topic_model) %>%
.[[1]]
topic_model
library(tidytext)
td_beta <- tidy(topic_model)
td_gamma <- tidy(topic_model, matrix = "gamma",
document_names = rownames(speechcorp))
library(ggthemes)
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
gamma_terms <- td_gamma %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
arrange(desc(gamma)) %>%
left_join(top_terms, by = "topic") %>%
mutate(topic = paste0("Topic ", topic),
topic = reorder(topic, gamma))
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.15,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
td_beta <- tidy(topic_model)
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
library(ggthemes)
top_terms <- td_beta %>%
arrange(beta) %>%
group_by(topic) %>%
top_n(7, beta) %>%
arrange(-beta) %>%
select(topic, term) %>%
summarise(terms = list(term)) %>%
mutate(terms = map(terms, paste, collapse = ", ")) %>%
unnest()
gamma_terms <- td_gamma %>%
group_by(topic) %>%
summarise(gamma = mean(gamma)) %>%
arrange(desc(gamma)) %>%
left_join(top_terms, by = "topic") %>%
mutate(topic = paste0("Topic ", topic),
topic = reorder(topic, gamma))
gamma_terms %>%
ggplot(aes(topic, gamma, label = terms, fill = topic)) +
geom_col(show.legend = FALSE) +
geom_text(hjust=0.6,size = 3,nudge_y = 0.15,
family = "IBMPlexSans") +
coord_flip() +
theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
theme(plot.title = element_text(size = 16,
family="IBMPlexSans-Bold"),
plot.subtitle = element_text(size = 13)) +
labs(x = NULL, y = expression(gamma),
title = "6 topics by prevalence in the Speech Corpus",
subtitle = "With the top words that contribute to each topic")
#stemming
speechcorp <- tokens(corpus, remove_punct = TRUE,
remove_symbols = TRUE, remove_numbers = TRUE) %>%
tokens_remove(stop) %>%
tokens_wordstem() %>%
tokens_ngrams(c(1,2))%>%
dfm() %>%
dfm_tolower()%>%
dfm_trim(min_termfreq = 5, min_docfreq = 0.0025, docfreq_type = "prop")
dfm_tfidf()
#stemming
speechcorp <- tokens(corpus, remove_punct = TRUE,
remove_symbols = TRUE, remove_numbers = TRUE) %>%
tokens_remove(stop) %>%
tokens_wordstem() %>%
tokens_ngrams(c(1,2))%>%
dfm() %>%
dfm_tolower()%>%
dfm_trim(min_termfreq = 5, min_docfreq = 0.0025, docfreq_type = "prop")%>%
dfm_tfidf()
speechcorp
textplot_wordcloud(speechcorp, random_order = FALSE, rotation = 0.25,
color = RColorBrewer::brewer.pal(12, "Dark2"),max_words =150,max_size = 4)
library(stm)
library(furrr)
many_models <- data_frame(K = c(2,3,4,5,6,7,8,9)) %>%
mutate(topic_model = future_map(K, ~stm(speechcorp, K = .,
verbose = FALSE)))
speechcorp<-dfm(speechcorp)
library(stm)
library(furrr)
many_models <- data_frame(K = c(2,3,4,5,6,7,8,9)) %>%
mutate(topic_model = future_map(K, ~stm(speechcorp, K = .,
verbose = FALSE)))
model<-stm(speechcorp, prevalence = ~dates,  K=7, seed=123)
?speechcorpo
?convert
speechcorp <- convert(speechcorp, to = "stm")
speechcorp <- convert(speechcorp, to = "lda")
speechcorp <- convert(speechcorp, to = "lda")
speechcorp <- convert(speechcorp, to = "lda")
speechcorp <- convert(speechcorp, to = "data.frame")
covidDfmlda <- convert(speechcorp, to = "lda")
View(speechcorp)
#stemming
speechcorp <- tokens(corpus, remove_punct = TRUE,
remove_symbols = TRUE, remove_numbers = TRUE) %>%
tokens_remove(stop) %>%
tokens_wordstem() %>%
tokens_ngrams(c(1,2))%>%
dfm() %>%
dfm_tolower()%>%
dfm_trim(min_termfreq = 5, min_docfreq = 0.0025, docfreq_type = "prop")%>%
dfm_tfidf()
speechcorp
textplot_wordcloud(speechcorp, random_order = FALSE, rotation = 0.25,
color = RColorBrewer::brewer.pal(12, "Dark2"),max_words =150,max_size = 4)
speechcorp<-as.data.frame(speechcorp)
words<-read.csv('/home/leon/Documents/GitHub/stat/Stats/Data/covidwords.csv')
odrer_words<-words[order(words$beta,decreasing =TRUE),][1:200]
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(quanteda) # quantitative analysis of textual data  (https://quanteda.io/articles/quickstart.html)
library(quanteda.textplots) # complementary to quanteda, for visualization
library(cld3) # for language detection
library(lda) # implementation of Latent Dirichlet Allocation
library(servr) # will be used for visualization
# library(topicmodels) # alternative to lda, several topic models included
library(stm) # for structural topic modeling
set.seed(5528) # set seed for reproductibility
library(corpus)
coronawords<-aggregate(final[final$count==1,]$n, list(final[final$count==1,]$FileName), sum)
covidwords<-filter(ap_topics, ap_topics$topic==3)
library(topicmodels)
ap_lda <- LDA(tdm, k = 4, control = list(seed = 1234))
library(tm)
tdm <- cast_dtm(data=book_tf_idf,term=word, document=FileName, n)
library(tidytext)
book_words <- speeches %>%
unnest_tokens(word, Content) %>%
count(FileName, word, sort = TRUE)
book_words <- book_words%>%
filter(!word %in% stop)
book_words <- book_words %>%
anti_join(stop_words)
total_words <- book_words %>%
group_by(FileName) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_tf_idf <- book_words %>%
bind_tf_idf(word, FileName, n)
library(tm)
tdm <- cast_dtm(data=book_tf_idf,term=word, document=FileName, n)
library(topicmodels)
ap_lda <- LDA(tdm, k = 4, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
top500<-top.topic.words(fit$topics,num.words=500)[1:500,1]
K <- 4 # number of topics
G <- 2000 # number of iterations
eta <- 1/K # Dirichlet hyperparamater for topic multinomials
alpha <- 1/K # Dirichlet hyperparameter for topic proportions
# fit the model
t1 <- Sys.time()
fit <- lda.collapsed.gibbs.sampler(documents = covidDfmlda$documents, K = K,
vocab = covidDfmlda$vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
#stemming
speechcorp2 <- tokens(corpus, remove_punct = TRUE,
remove_symbols = TRUE, remove_numbers = TRUE) %>%
tokens_remove(stop) %>%
tokens_wordstem() %>%
tokens_ngrams(c(1,2))%>%
dfm() %>%
dfm_tolower()%>%
dfm_trim(min_termfreq = 5, min_docfreq = 0.0025, docfreq_type = "prop")
#dfm_tfidf()
speechcorp
textplot_wordcloud(speechcorp, random_order = FALSE, rotation = 0.25,
color = RColorBrewer::brewer.pal(12, "Dark2"),max_words =150,max_size = 4)
covidDfmlda <- convert(speechcorp2, to = "lda")
K <- 4 # number of topics
G <- 2000 # number of iterations
eta <- 1/K # Dirichlet hyperparamater for topic multinomials
alpha <- 1/K # Dirichlet hyperparameter for topic proportions
# fit the model
t1 <- Sys.time()
fit <- lda.collapsed.gibbs.sampler(documents = covidDfmlda$documents, K = K,
vocab = covidDfmlda$vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
t2 <- Sys.time()
t2 - t1
top500<-top.topic.words(fit$topics,num.words=500)[1:500,1]
library(dplyr)
david<-select(speechcorp, c(doc_id,top500))
finaldavid<-cbind(dates,david )
top500<-top.topic.words(fit$topics,num.words=500)[1:500,1]
top500
fit$topics
fit$topics
top500
top500<-as.dataframe(top.topic.words(fit$topics,num.words=500)[1:500,1])
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:500,1])
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:500])
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:500])
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:500])
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:500,])
View(top500)
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:500,2])
top500<-as.data.frame(top.topic.words(fit$topics,num.words=500)[1:200,2])
library(dplyr)
david<-select(speechcorp, c(doc_id,top500))
top500<-as.data.frame(top.topic.words(fit$topics,num.words=200)[,2])
library(dplyr)
david<-select(speechcorp, c(doc_id,top500))
View(top500)
top500<-top.topic.words(fit$topics,num.words=200)[,2]
library(dplyr)
david<-select(speechcorp, c(doc_id,top500))
finaldavid<-cbind(dates,david)
speeches<-read_csv('output_file.csv',show_col_types = FALSE)
dates=c('28-01-2020','12-09-2020','20-06-2020','18-08-2020','19-09-2020','10-09-2020','28-08-2020','14-01-2020','13-03-2020','08-08-2020','28-02-2020','10-02-2020','15-04-2020','03-09-2020','19-02-2020','30-01-2020','01-06-2020','01-09-2020','20-02-2020','07-09-2020','11-03-2020','13-09-2020','17-09-2020','04-07-2020','08-09-2020','02-03-2020','23-04-2020','22-09-2020','18-09-2020','13-04-2020','21-02-2020','21-09-2020','05-11-2020')
#dates<-str_split_fixed(speeches$FileName,pattern='(.{3}\\d\\d_\\d{4}(?=.txt$))',n=33)
library(dplyr)
david<-select(speechcorp, c(doc_id,top500))
finaldavid<-cbind(dates,david)
finaldavid$dates<-as.Date(finaldavid$dates)
write.csv(finaldavid, 'lassotopwords.csv')
library(lme4)
fe<- lmer(formula=observed ~ X1+X2+Covid_topic_prop+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
summary(fe)
summary(fe)
library(lme4)
setwd("/home/leon/Documents/GitHub/stat/Stats/Data")
data<-read.csv('Social_distancing_model_data.csv')
fe<- lmer(formula=observed ~ X1+X2+Covid_topic_prop+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
summary(fe)
summary(fe)
stargazer(fe)
library(stargazer)
stargazer(fe)
fe1<- lmer(formula=observed ~ X1+X2+Covid_topic_prop+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
fe2<- lmer(formula=observed ~ Covid_topic_prop+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
stargazer(fe1,fe2)
stargazer(fe2,fe1)
fe1<- lmer(formula=observed ~ +Covid_topic_prop+X1+X2+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
fe2<- lmer(formula=observed ~ Covid_topic_prop+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
stargazer(fe2,fe1)
fe1<- lmer(formula=observed ~ +Covid_topic_prop+X1+X2+X3+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
View(data)
fe1<- lmer(formula=observed ~ +Covid_topic_prop+X1+X2+X4+covid_cases+strictness_measure+(X1+X2+Covid_topic_prop+covid_cases+strictness_measure|state), data=data)
